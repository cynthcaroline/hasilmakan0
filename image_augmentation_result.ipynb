{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "import numpy as np\n",
    "from scipy.misc import imresize\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import shutil\n",
    "import stat\n",
    "import collections\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Load dataset images and resize to meet minimum width and height pixel size\n",
    "def load_images(root, min_side=299):\n",
    "    all_imgs = []\n",
    "    all_classes = []\n",
    "    resize_count = 0\n",
    "    invalid_count = 0\n",
    "    for i, subdir in enumerate(listdir(root)):\n",
    "        imgs = listdir(join(root, subdir))\n",
    "        class_ix = class_to_ix[subdir]\n",
    "        print(i, class_ix, subdir)\n",
    "        for img_name in imgs:\n",
    "            img_arr = img.imread(join(root, subdir, img_name))\n",
    "            img_arr_rs = img_arr\n",
    "            try:\n",
    "                w, h, _ = img_arr.shape\n",
    "                if w < min_side:\n",
    "                    wpercent = (min_side/float(w))\n",
    "                    hsize = int((float(h)*float(wpercent)))\n",
    "                    #print('new dims:', min_side, hsize)\n",
    "                    img_arr_rs = imresize(img_arr, (min_side, hsize))\n",
    "                    resize_count += 1\n",
    "                elif h < min_side:\n",
    "                    hpercent = (min_side/float(h))\n",
    "                    wsize = int((float(w)*float(hpercent)))\n",
    "                    #print('new dims:', wsize, min_side)\n",
    "                    img_arr_rs = imresize(img_arr, (wsize, min_side))\n",
    "                    resize_count += 1\n",
    "                all_imgs.append(img_arr_rs)\n",
    "                all_classes.append(class_ix)\n",
    "            except:\n",
    "                print('Lewatkan gambar yang jelek: ', subdir, img_name)\n",
    "                invalid_count += 1\n",
    "    print(len(all_imgs), 'Gambar dimuat')\n",
    "    print(resize_count, 'Gambar diubah ukurannya')\n",
    "    print(invalid_count, 'Gambar yang dilewatkan')\n",
    "    return np.array(all_imgs), np.array(all_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## augmentasi dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "num_processes = 6\n",
    "pool = mp.Pool(processes=num_processes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kelas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_ix = {}\n",
    "ix_to_class = {}\n",
    "with open('metadata/meta/classes.txt', 'r') as txt:\n",
    "    classes = [l.strip() for l in txt.readlines()]\n",
    "    class_to_ix = dict(zip(classes, range(len(classes))))\n",
    "    ix_to_class = dict(zip(range(len(classes)), classes))\n",
    "    class_to_ix = {v: k for k, v in ix_to_class.items()}\n",
    "sorted_class_to_ix = collections.OrderedDict(sorted(class_to_ix.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## memuat dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 apple_pie\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:27: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "C:\\Users\\User\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:21: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 baby_back_ribs\n",
      "2 2 baklava\n",
      "3 3 beef_carpaccio\n",
      "4 4 beef_tartare\n",
      "5 5 beet_salad\n",
      "6 6 beignets\n",
      "7 7 bibimbap\n",
      "8 8 bread_pudding\n",
      "Lewatkan gambar yang jelek:  bread_pudding 1375816.jpg\n",
      "9 9 breakfast_burrito\n",
      "10 10 bruschetta\n",
      "11 11 caesar_salad\n",
      "12 12 cannoli\n",
      "13 13 caprese_salad\n",
      "14 14 carrot_cake\n",
      "15 15 ceviche\n",
      "16 16 cheesecake\n",
      "17 17 cheese_plate\n",
      "18 18 chicken_curry\n",
      "19 19 chicken_quesadilla\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "y_train = load_images('food-101/train', min_side=299)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = load_images('food-101/test', min_side=299)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 102\n",
    "y_train_cat = to_categorical(y_train, nb_classes=n_classes)\n",
    "y_test_cat = to_categorical(y_test, nb_classes=n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import Input\n",
    "\n",
    "import tools.image_gen_extended as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = T.ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    "    vertical_flip=False, # randomly flip images\n",
    "    zoom_range=[.8, 1],\n",
    "    channel_shift_range=30,\n",
    "    fill_mode='reflect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = T.ImageDataGenerator()\n",
    "test_datagen.config['random_crop_size'] = (299, 299)\n",
    "test_datagen.set_pipeline([T.random_transform, T.random_crop, T.preprocess_input])\n",
    "test_generator = test_datagen.flow(X_test, y_test_cat, batch_size=64, seed=11, pool=pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_preprocess_input(x0):\n",
    "    x = x0 / 2.0\n",
    "    x += 0.5\n",
    "    x *= 255.\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(unprocess=True):\n",
    "    for x in test_generator:\n",
    "        fig, axes = plt.subplots(nrows=8, ncols=4)\n",
    "        fig.set_size_inches(8, 8)\n",
    "        page = 0\n",
    "        page_size = 32\n",
    "        start_i = page * page_size\n",
    "        for i, ax in enumerate(axes.flat):\n",
    "            img = x[0][i+start_i]\n",
    "            if unprocess:\n",
    "                im = ax.imshow( reverse_preprocess_input(img).astype('uint8') )\n",
    "            else:\n",
    "                im = ax.imshow(img)\n",
    "            ax.set_axis_off()\n",
    "            ax.title.set_visible(False)\n",
    "            ax.xaxis.set_ticks([])\n",
    "            ax.yaxis.set_ticks([])\n",
    "            for spine in ax.spines.values():\n",
    "                spine.set_visible(False)\n",
    "\n",
    "        plt.subplots_adjust(left=0, wspace=0, hspace=0)\n",
    "        plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "show_images(unprocess=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
